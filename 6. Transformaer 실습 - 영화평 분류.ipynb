{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e3bb8-527a-46c6-9fc4-0328a064bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 80, 32)            320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 64)                6208      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 326338 (1.24 MB)\n",
      "Trainable params: 326338 (1.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이 예제는 `2. RNN 실습 - 영화평 분류`\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import SimpleRNN, Dense, Input, Embedding\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=(80,))) # 입력하는 영화평의 길이를 80으로 제한, 길면 자르고, 짧으면 zero padding\n",
    "# model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "# model.add(SimpleRNN(64))\n",
    "# model.add(Dense(2, activation='softmax')) # model.add(Dense(1, activation='sigmoid'))\n",
    "# model.summary()\n",
    "\n",
    "# 이 모델의 test set accuracy는 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c7484a-7c63-419b-bc71-6e5a7520082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 80)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 80, 32)               320000    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 80, 32)               0         ['embedding[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 80, 32)               8416      ['tf.__operators__.add[0][0]',\n",
      " iHeadAttention)                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " add (Add)                   (None, 80, 32)               0         ['tf.__operators__.add[0][0]',\n",
      "                                                                     'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 80, 32)               128       ['add[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 80, 32)               4192      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 80, 32)               0         ['sequential[0][0]',          \n",
      "                                                                     'batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 80, 32)               128       ['add_1[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 32)                   0         ['batch_normalization_1[0][0]'\n",
      " GlobalAveragePooling1D)                                            ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 32)                   0         ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   2112      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    130       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335106 (1.28 MB)\n",
      "Trainable params: 334978 (1.28 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transformer를 이용한 영화평 분류\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "inputs = layers.Input(shape=(80,))\n",
    "\n",
    "input_embedding = layers.Embedding(input_dim=10000, output_dim=32)(inputs)\n",
    "positions = tf.range(start=0, limit=80)\n",
    "pos_encoding = layers.Embedding(input_dim=80, output_dim=32)(positions)\n",
    "pos_enc_output = pos_encoding + input_embedding\n",
    "\n",
    "attention_output = layers.MultiHeadAttention(num_heads=2, key_dim=32)(pos_enc_output, pos_enc_output)\n",
    "x = layers.add([pos_enc_output, attention_output])\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "ffnn = Sequential([layers.Dense(64, activation=\"relu\"), \n",
    "                   layers.Dense(32, activation=\"relu\")])(x)\n",
    "x = layers.add([ffnn, x])\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d441c95-8cfa-424c-bff7-0ca07b5ee8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb67f2f-7b73-4513-a2aa-7ddb5fd27cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n",
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5522cb80-c068-4b89-9152-db2a84310941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, truncating='post', padding='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf49cac-73fd-4f6c-bf10-7410080c3fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 22s 159ms/step - loss: 0.4931 - accuracy: 0.7553\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.3187 - accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.2596 - accuracy: 0.8918\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 156ms/step - loss: 0.2091 - accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.1664 - accuracy: 0.9244\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.1386 - accuracy: 0.9362\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.1096 - accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 19s 156ms/step - loss: 0.0911 - accuracy: 0.9635\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0650 - accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.0493 - accuracy: 0.9830\n",
      "CPU times: total: 2min 35s\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d690e278d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_pad, y_train, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9592949-9039-4f56-b4c7-aaf10dda66b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 1.3055 - accuracy: 0.6165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3055187463760376, 0.6164799928665161]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9871fb65-5168-4700-b0fc-ceea109d6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78be4ad-f3bc-4491-aa19-19ea405b5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = model.predict(X_test_pad)\n",
    "# pred = (pred > 0.5).astype(int)\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d81e2f-79b0-4951-9cb9-7ff0ec51ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8570 3930]\n",
      " [5658 6842]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50b5985-3cad-4ea8-a6d3-b249ee5bc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61648"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe57650-9039-4065-92d1-6e9ea3bb4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저를 sgd로 바꿔보세요. accuracy: 0.57784\n",
    "# 전체 단어의 개수를 1000개로 바꿔보세요. accuracy:\n",
    "# 영화평의 길이를 200개로 바꿔보세요. accuracy:\n",
    "# pad_sequence의 truncating과 padding을 pre로 바꿔보세요. accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f95327-4c20-401d-b00b-39427aa05552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 택스트를 긍/부정 분류하세요.\n",
    "text = \"My God the actors who potrayed the VIP people cannot act. I cringed everytime they said a line. It felt like they were just reading them. Even the intonation was off. It was like when we were kids and had to read a play in class and we exagerated the intonation. Terrible, just awful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b2c664-aa01-4d76-aab1-8f9bbefe3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "# print(word_index)\n",
    "# {'fawn': 34701, 'tsukino': 52006, 'nunnery': 52007,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "253ed3c5-c674-45f2-980b-08c305a562a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {k:(v+3) for k,v in word_index.items()}\n",
    "word_to_idx[\"<PAD>\"] = 0\n",
    "word_to_idx[\"<START>\"] = 1\n",
    "word_to_idx[\"<UNK>\"] = 2  # unknown\n",
    "word_to_idx[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e89c7e2-397f-48e8-bd1f-31952b42d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'god', 'the', 'actors', 'who', 'potrayed', 'the', 'vip', 'people', 'cannot', 'act.', 'i', 'cringed', 'everytime', 'they', 'said', 'a', 'line.', 'it', 'felt', 'like', 'they', 'were', 'just', 'reading', 'them.', 'even', 'the', 'intonation', 'was', 'off.', 'it', 'was', 'like', 'when', 'we', 'were', 'kids', 'and', 'had', 'to', 'read', 'a', 'play', 'in', 'class', 'and', 'we', 'exagerated', 'the', 'intonation.', 'terrible,', 'just', 'awful.']\n"
     ]
    }
   ],
   "source": [
    "input_text = text.lower().split()\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6056813d-003a-4700-853c-a5e4fbbe425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 숫자로 변환합니다. \n",
    "# word_to_idx에 없는 단어는 2(<UNK>)로 지정하며, \n",
    "# 인덱스가 10000보다 크면 3(<UNUSED>)로 지정합니다.\n",
    "def encoding(review_text):\n",
    "  encoded = []\n",
    "  for word in review_text:\n",
    "    try:\n",
    "      idx = word_to_idx[word]\n",
    "      if idx>10000:\n",
    "        encoded.append(3)\n",
    "      else:\n",
    "        encoded.append(idx)\n",
    "    except:\n",
    "      encoded.append(2)\n",
    "  return encoded\n",
    "\n",
    "input_encoded = encoding(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0bf4c9-244a-43fe-b72d-2ee076c7df4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61, 558,   4, 156,  37,   2,   4,   3,  84, 566,   2,  13,   3,\n",
       "          3,  36, 301,   6,   2,  12, 421,  40,  36,  71,  43, 886,   2,\n",
       "         60,   4,   3,  16,   2,  12,  16,  40,  54,  75,  71, 362,   5,\n",
       "         69,   8, 332,   6, 297,  11, 707,   5,  75,   3,   4,   2,   2,\n",
       "         43,   2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(input_encoded)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feab6109-b316-4204-a003-9c2f56b37c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pad = pad_sequences(\n",
    "    np.array(input_encoded)[np.newaxis, :],\n",
    "    maxlen=80, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8635c5-fffe-4f55-b544-0c49eb6439ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08314691, 0.9168531 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_pad) # LSTM을 이용한 인공신경망 모형은 부정(0)으로 분류함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b567b-7c6d-4bab-be62-6abc00481d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
