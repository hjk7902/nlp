{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e3bb8-527a-46c6-9fc4-0328a064bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 예제는 `2. RNN 실습 - 영화평 분류`\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import SimpleRNN, Dense, Input, Embedding\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=(80,))) # 입력하는 영화평의 길이를 80으로 제한, 길면 자르고, 짧으면 zero padding\n",
    "# model.add(Embedding(input_dim=10000, output_dim=32))\n",
    "# model.add(SimpleRNN(64))\n",
    "# model.add(Dense(2, activation='softmax')) # model.add(Dense(1, activation='sigmoid'))\n",
    "# model.summary()\n",
    "\n",
    "# 이 모델의 test set accuracy는 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afd00e5-8b06-45ae-aff3-7eb8fbd42e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# MultiHeadAttention 레이어 정의\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        # MultiHeadAttention 클래스 초기화 메소드\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads  # 헤드 수\n",
    "        self.key_dim = key_dim  # 각 헤드의 차원\n",
    "        self.depth = key_dim // num_heads  # 각 헤드의 깊이\n",
    "        \n",
    "        # Query, Key, Value를 생성하기 위한 밀집 레이어\n",
    "        self.wq = layers.Dense(key_dim)\n",
    "        self.wk = layers.Dense(key_dim)\n",
    "        self.wv = layers.Dense(key_dim)\n",
    "        \n",
    "        # 마지막 출력 밀집 레이어\n",
    "        self.dense = layers.Dense(key_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # (batch_size, seq_len, key_dim) -> (batch_size, num_heads, seq_len, depth)로 변환\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        # (batch_size, seq_len, num_heads, depth) -> (batch_size, num_heads, seq_len, depth)로 전치\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q):\n",
    "        # 입력 시퀀스의 배치 크기\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        # 입력 텐서를 Query, Key, Value로 변환\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        # 각 헤드로 분할\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # 스케일드 닷 프로덕트 어텐션 계산\n",
    "        scaled_attention, attention_weights = self.scaled_dot_product_attention(q, k, v)\n",
    "        \n",
    "        # 각 헤드의 출력을 결합하여 원래의 형태로 변환\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.key_dim))\n",
    "        \n",
    "        # 마지막 밀집 레이어를 통과하여 최종 출력 생성\n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def scaled_dot_product_attention(self, q, k, v):\n",
    "        # Query와 Key의 내적을 계산\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        \n",
    "        # 스케일링을 위해 Key의 차원으로 나눔\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        \n",
    "        # 어텐션 가중치를 소프트맥스로 계산\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        \n",
    "        # 어텐션 가중치를 Value에 곱하여 최종 어텐션 출력 계산\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        \n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c7484a-7c63-419b-bc71-6e5a7520082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 80)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 80, 32)               320000    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 80, 32)               0         ['embedding[0][0]']           \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 32)             4224      ['tf.__operators__.add[0][0]',\n",
      " iHeadAttention)                                                     'tf.__operators__.add[0][0]',\n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " add (Add)                   (None, 80, 32)               0         ['tf.__operators__.add[0][0]',\n",
      "                                                                     'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 80, 32)               128       ['add[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 80, 32)               4192      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 80, 32)               0         ['sequential[0][0]',          \n",
      "                                                                     'batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 80, 32)               128       ['add_1[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 32)                   0         ['batch_normalization_1[0][0]'\n",
      " GlobalAveragePooling1D)                                            ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 32)                   0         ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64)                   2112      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 64)                   0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 2)                    130       ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 330914 (1.26 MB)\n",
      "Trainable params: 330786 (1.26 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transformer를 이용한 영화평 분류\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "inputs = layers.Input(shape=(80,))\n",
    "\n",
    "input_embedding = layers.Embedding(input_dim=10000, output_dim=32)(inputs)\n",
    "positions = tf.range(start=0, limit=80)\n",
    "pos_encoding = layers.Embedding(input_dim=80, output_dim=32)(positions)\n",
    "pos_enc_output = pos_encoding + input_embedding\n",
    "\n",
    "# attention_output = layers.MultiHeadAttention(num_heads=2, key_dim=32)(pos_enc_output, pos_enc_output)\n",
    "attention_output = MultiHeadAttention(num_heads=3, key_dim=32)(pos_enc_output, pos_enc_output, pos_enc_output)\n",
    "x = layers.add([pos_enc_output, attention_output])\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "ffnn = Sequential([layers.Dense(64, activation=\"relu\"), \n",
    "                   layers.Dense(32, activation=\"relu\")])(x)\n",
    "x = layers.add([ffnn, x])\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d441c95-8cfa-424c-bff7-0ca07b5ee8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb67f2f-7b73-4513-a2aa-7ddb5fd27cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,) (25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5522cb80-c068-4b89-9152-db2a84310941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train, maxlen=80, truncating='post', padding='post')\n",
    "X_test_pad = pad_sequences(X_test, maxlen=80, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf49cac-73fd-4f6c-bf10-7410080c3fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 16s 114ms/step - loss: 0.4967 - accuracy: 0.7482\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.3211 - accuracy: 0.8660\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.2627 - accuracy: 0.8914\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.2116 - accuracy: 0.9096\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 14s 113ms/step - loss: 0.1668 - accuracy: 0.9262\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.1272 - accuracy: 0.9470\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.0936 - accuracy: 0.9632\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 15s 121ms/step - loss: 0.0670 - accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 15s 120ms/step - loss: 0.0610 - accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.0522 - accuracy: 0.9817\n",
      "CPU times: total: 1min 39s\n",
      "Wall time: 2min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1846d56b450>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_pad, y_train, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9592949-9039-4f56-b4c7-aaf10dda66b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step - loss: 2.0335 - accuracy: 0.7748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.033520221710205, 0.7748399972915649]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9871fb65-5168-4700-b0fc-ceea109d6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e78be4ad-f3bc-4491-aa19-19ea405b5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = model.predict(X_test_pad)\n",
    "# pred = (pred > 0.5).astype(int)\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d81e2f-79b0-4951-9cb9-7ff0ec51ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9489 3011]\n",
      " [2618 9882]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50b5985-3cad-4ea8-a6d3-b249ee5bc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77484"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe57650-9039-4065-92d1-6e9ea3bb4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저를 sgd로 바꿔보세요. accuracy: 0.57784\n",
    "# 전체 단어의 개수를 1000개로 바꿔보세요. accuracy:\n",
    "# 영화평의 길이를 200개로 바꿔보세요. accuracy:\n",
    "# pad_sequence의 truncating과 padding을 pre로 바꿔보세요. accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f95327-4c20-401d-b00b-39427aa05552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 택스트를 긍/부정 분류하세요.\n",
    "text = \"My God the actors who potrayed the VIP people cannot act. I cringed everytime they said a line. It felt like they were just reading them. Even the intonation was off. It was like when we were kids and had to read a play in class and we exagerated the intonation. Terrible, just awful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b2c664-aa01-4d76-aab1-8f9bbefe3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "# print(word_index)\n",
    "# {'fawn': 34701, 'tsukino': 52006, 'nunnery': 52007,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "253ed3c5-c674-45f2-980b-08c305a562a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {k:(v+3) for k,v in word_index.items()}\n",
    "word_to_idx[\"<PAD>\"] = 0\n",
    "word_to_idx[\"<START>\"] = 1\n",
    "word_to_idx[\"<UNK>\"] = 2  # unknown\n",
    "word_to_idx[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e89c7e2-397f-48e8-bd1f-31952b42d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'god', 'the', 'actors', 'who', 'potrayed', 'the', 'vip', 'people', 'cannot', 'act.', 'i', 'cringed', 'everytime', 'they', 'said', 'a', 'line.', 'it', 'felt', 'like', 'they', 'were', 'just', 'reading', 'them.', 'even', 'the', 'intonation', 'was', 'off.', 'it', 'was', 'like', 'when', 'we', 'were', 'kids', 'and', 'had', 'to', 'read', 'a', 'play', 'in', 'class', 'and', 'we', 'exagerated', 'the', 'intonation.', 'terrible,', 'just', 'awful.']\n"
     ]
    }
   ],
   "source": [
    "input_text = text.lower().split()\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6056813d-003a-4700-853c-a5e4fbbe425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 숫자로 변환합니다. \n",
    "# word_to_idx에 없는 단어는 2(<UNK>)로 지정하며, \n",
    "# 인덱스가 10000보다 크면 3(<UNUSED>)로 지정합니다.\n",
    "def encoding(review_text):\n",
    "  encoded = []\n",
    "  for word in review_text:\n",
    "    try:\n",
    "      idx = word_to_idx[word]\n",
    "      if idx>10000:\n",
    "        encoded.append(3)\n",
    "      else:\n",
    "        encoded.append(idx)\n",
    "    except:\n",
    "      encoded.append(2)\n",
    "  return encoded\n",
    "\n",
    "input_encoded = encoding(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0bf4c9-244a-43fe-b72d-2ee076c7df4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61, 558,   4, 156,  37,   2,   4,   3,  84, 566,   2,  13,   3,\n",
       "          3,  36, 301,   6,   2,  12, 421,  40,  36,  71,  43, 886,   2,\n",
       "         60,   4,   3,  16,   2,  12,  16,  40,  54,  75,  71, 362,   5,\n",
       "         69,   8, 332,   6, 297,  11, 707,   5,  75,   3,   4,   2,   2,\n",
       "         43,   2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(input_encoded)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feab6109-b316-4204-a003-9c2f56b37c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pad = pad_sequences(\n",
    "    np.array(input_encoded)[np.newaxis, :],\n",
    "    maxlen=80, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b8635c5-fffe-4f55-b544-0c49eb6439ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95886034, 0.04113967]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_pad) # LSTM을 이용한 인공신경망 모형은 부정(0)으로 분류함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b567b-7c6d-4bab-be62-6abc00481d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
