{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cae7a7-5a94-44ab-ab48-6466e3ec442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Embedding, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663f2a22-c431-41ab-81b8-567b723607a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 64)           320000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 64)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200)               132000    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1206      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453206 (1.73 MB)\n",
      "Trainable params: 453206 (1.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(200,))) # 입력하는 단어의 개수를 200개로 제한\n",
    "model.add(Embedding(input_dim=5000, output_dim=64))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c3dfd5-2668-4f12-a201-8ba7cab5ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaa1010-204f-4c4b-8b05-a300d876feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weren', 'theirs', 'that', 'his', 'about', 'being', 'here', 'am', \"couldn't\", 'shouldn', 'which', 'when', 'themselves', 'all', 'they', 'wasn', 'did', 'only', 't', 'who', \"doesn't\", 'during', 'ain', \"you've\", 'your', 'too', \"won't\", 'and', 'haven', 'from', 'as', 'then', 'be', 'yours', 'under', 're', 'this', 'itself', 'of', 've', 'myself', 'above', 'very', 'between', 'you', 'don', 'whom', 'hasn', 'not', 'me', 'him', 'aren', 'm', 'just', 'having', 'ma', 'again', \"you'll\", 'yourselves', 'ours', 'in', \"haven't\", 'mustn', 'most', \"don't\", 'further', 'there', 'how', 'same', 'should', 'while', 'into', 'why', 'y', 'to', \"didn't\", 'is', 'so', 'no', 'than', 'my', \"you're\", 'up', 'where', 'what', \"you'd\", 'each', \"it's\", 'at', 'own', 'both', \"wouldn't\", 'were', 'against', 'a', 'by', 'for', 'its', 'these', 'on', 'd', 'i', 'needn', 'if', 'doesn', 'she', 'them', 'our', 'yourself', 'he', \"should've\", 'below', 'now', 'her', 'over', 'ourselves', 'their', 's', \"mightn't\", 'll', 'wouldn', 'have', 'couldn', 'some', 'had', 'has', 'hadn', 'nor', \"needn't\", 'few', 'other', 'won', 'it', 'we', 'out', 'such', \"aren't\", \"mustn't\", \"wasn't\", 'more', 'didn', \"weren't\", 'an', 'any', 'will', 'shan', \"hasn't\", 'those', 'down', 'isn', \"shouldn't\", 'does', 'doing', \"hadn't\", 'o', 'but', 'with', \"shan't\", 'off', 'are', 'once', \"she's\", 'do', 'the', 'was', 'himself', 'hers', 'or', 'until', 'through', 'before', 'after', 'mightn', \"isn't\", 'herself', 'been', \"that'll\", 'can', 'because'}\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9858ac-1c38-492a-abe6-bd9bc32b4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "original = [] # 기사 원본 저장\n",
    "processed = [] # 전처리된 기사 저장\n",
    "labels = [] # 기사 카테고리\n",
    "\n",
    "with open('bbc-text.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader) # 첫 번째 행은 메타정보를 가지고 있으므로 건너뜀\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        original.append(row[1])\n",
    "\n",
    "        news = row[1]\n",
    "        for word in stopwords:\n",
    "            token = ' ' + word + ' ' # 단어단위로 불용어를 제거해야 하므로...\n",
    "            news = news.replace(token, ' ')\n",
    "        processed.append(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e1371e-5d84-47e5-9a44-67a289553916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels[0], processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd10c717-bdea-4688-8c55-990883f347de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "A_token = Tokenizer(num_words=5000, oov_token='OOV') # 단어사전에 없는 토큰들은 OOV로 표시\n",
    "A_token.fit_on_texts(processed)\n",
    "A_tokenized = A_token.texts_to_sequences(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f66b34-285e-4857-8b9b-1914ed7d507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(A_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe0b0ad-d267-406b-86e4-f79d133a7fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "A_tokenized_seq = pad_sequences(A_tokenized, maxlen=200, padding='post', truncating='post')\n",
    "type(A_tokenized_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1ff6d6-3aa1-4fe2-ab0b-bf35269e34c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(2225,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "C_token = Tokenizer()\n",
    "C_token.fit_on_texts(labels)\n",
    "C_tokenized = C_token.texts_to_sequences(labels)\n",
    "print(type(C_tokenized))\n",
    "C_tokenized = np.array(C_tokenized).reshape(-1)\n",
    "print(C_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3df2d2-c1ab-4d33-b02c-17ecc59e246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'sport', 2: 'business', 3: 'politics', 4: 'tech', 5: 'entertainment'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_label = {}\n",
    "for label, index in C_token.word_index.items():\n",
    "    idx_to_label[index] = label\n",
    "print(idx_to_label) # 라벨의 인덱스가 1부터 시작하므로 뉴런의 수를 6개로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd57c570-9540-4f6a-921b-2bfc7b64a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(A_tokenized_seq, C_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667af500-932d-4fe8-af98-1863b495b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d997d7b-5e9b-4d63-b4e4-afd93c1ae52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 1.7614 - accuracy: 0.2674\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 1.5882 - accuracy: 0.2854\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 13s 1s/step - loss: 1.5153 - accuracy: 0.3147\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 14s 2s/step - loss: 1.4842 - accuracy: 0.3969\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.4246 - accuracy: 0.3861\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.1518 - accuracy: 0.5797\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.0404 - accuracy: 0.6043\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.7999 - accuracy: 0.8231\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.6345 - accuracy: 0.8153\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.4765 - accuracy: 0.8717\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.3269 - accuracy: 0.8921\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.2882 - accuracy: 0.9119\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.2091 - accuracy: 0.9221\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.1770 - accuracy: 0.9341\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.1254 - accuracy: 0.9694\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0792 - accuracy: 0.9826\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0603 - accuracy: 0.9892\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.0510 - accuracy: 0.9934\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0520 - accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 15s 2s/step - loss: 0.0476 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13f9b1e5590>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "230e9f7e-4666-46f8-82d2-6f5c3e904ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 28ms/step - loss: 0.1639 - accuracy: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16394966840744019, 0.9551166892051697]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56fb3848-8329-41a7-8542-c1fe4c671fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = ['''\n",
    "Fast bowler Josh Hazlewood has admitted that it is in Australia's \"best interest\" for England to be eliminated in the T20 World Cup group stage.\n",
    "\n",
    "Australia qualified for the Super 8s with a comprehensive nine-wicket win over Namibia, leaving England and Scotland to battle it out for second place.\n",
    "\n",
    "Jos Buttler's side need to beat Oman and Namibia to have any chance of progressing but, even if they do, net run-rate could determine who goes through.\n",
    "\n",
    "That would give Australia, who face Scotland on Sunday, a potentially key role in determining who else will advance from Group B.\n",
    "\n",
    "\n",
    "A Scotland win would send them through and eliminate England but, with Richie Berrington's team currently boasting a vastly superior net run-rate to England, even a narrow Australia victory could be enough to knock out the defending champions.\n",
    "\n",
    "Asked if Australia would try to make things as difficult as possible for England, Hazlewood said: \"Yeah, I think so.\n",
    "\n",
    "\"In this tournament you potentially come up against England at some stage again and they're probably one of the top few teams on their day.\n",
    "\n",
    "\"We've had some real struggles against them in T20 cricket so if we can get them out of the tournament that's in our best interest, as well as probably everyone else's.\"\n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be4a9ba-dbde-466f-b104-5e0e367ea037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "news[0] = re.sub(r'[^\\w\\s]', '', news[0]) # 구둣점 제거\n",
    "for word in stopwords:\n",
    "    token = ' ' + word + ' '\n",
    "    news[0] = news[0].replace(token, ' ')\n",
    "# print(news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9000845-d195-4d0e-9aee-5d8010d90c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_seq = A_token.texts_to_sequences(news)\n",
    "news_padded = pad_sequences(news_seq, maxlen=200, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bde4d23c-f47e-4a97-9ddf-d902c481823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 395ms/step\n",
      "sport\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(news_padded)\n",
    "print(idx_to_label[np.argmax(pred[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ff765bf-4c0d-415c-b4d6-4cedbce2a63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
